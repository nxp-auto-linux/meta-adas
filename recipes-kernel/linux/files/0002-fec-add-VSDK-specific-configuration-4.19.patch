From a394cee81458b357221375e8026c0ff8a28a1d4d Wed Nov 27 14:01:41 2019 +0100
From: Zdenek Valek <zdenek.valek@nxp.com>
Date: Wed Mar 4 13:03:48 2020 +0100
Subject: [PATCH 2/2] fec: add VSDK specific configuration

Signed-off-by: Ludovit Minarik <ludovit.minarik@nxp.com>
Signed-off-by: Catalin Udma <catalin-dan.udma@nxp.com>
Signed-off-by: Zdenek Valek <zdenek.valek@nxp.com>
---

diff --git a/drivers/net/ethernet/freescale/fec.h b/drivers/net/ethernet/freescale/fec.h
index 24d34e895a0e..4636e010ad46 100644
--- a/drivers/net/ethernet/freescale/fec.h
+++ b/drivers/net/ethernet/freescale/fec.h
@@ -327,9 +327,9 @@ struct bufdesc_ex {
 #define RCMR_MATCHEN		(0x1 << 16)
 #define RCMR_CMP_CFG(v, n)	(((v) & 0x7) <<  (n << 2))
 #define RCMR_CMP_1		(RCMR_CMP_CFG(0, 0) | RCMR_CMP_CFG(1, 1) | \
-				RCMR_CMP_CFG(2, 2) | RCMR_CMP_CFG(3, 3))
-#define RCMR_CMP_2		(RCMR_CMP_CFG(4, 0) | RCMR_CMP_CFG(5, 1) | \
-				RCMR_CMP_CFG(6, 2) | RCMR_CMP_CFG(7, 3))
+				RCMR_CMP_CFG(3, 2) | RCMR_CMP_CFG(4, 3))
+#define RCMR_CMP_2		(RCMR_CMP_CFG(2, 0) | RCMR_CMP_CFG(2, 1) | \
+				RCMR_CMP_CFG(2, 2) | RCMR_CMP_CFG(2, 3))
 #define RCMR_CMP(X)		(((X) == 1) ? RCMR_CMP_1 : RCMR_CMP_2)
 #define FEC_TX_BD_FTYPE(X)	(((X) & 0xf) << 20)
 
@@ -514,8 +514,16 @@ struct fec_enet_private {
 
 	bool ptp_clk_on;
 	struct mutex ptp_clk_mutex;
-	unsigned int num_tx_queues;
-	unsigned int num_rx_queues;
+	/*  Number of queues which shall be enabled by the driver
+	    (the driver is responsible for the whole controller) */
+	unsigned int num_tx_queues; /* Number of HW supported TX queues */
+	unsigned int num_rx_queues; /* Number of HW supported RX queues */
+	/*  Number of queues actually handled by the driver. Some queues
+	    may have different handling sw thus the driver will not use them. */
+	/*  Number of tx queues handled by the driver */
+	unsigned int num_tx_queues_served;
+	/*  Number of rx queues handled by the driver */
+	unsigned int num_rx_queues_served;
 
 	/* The saved address of a sent-in-place packet/buffer, for skfree(). */
 	struct fec_enet_priv_tx_q *tx_queue[FEC_ENET_MAX_TX_QS];
diff --git a/drivers/net/ethernet/freescale/fec_main.c b/drivers/net/ethernet/freescale/fec_main.c
index 35dc23010c57..23c89b5b10f3 100644
--- a/drivers/net/ethernet/freescale/fec_main.c
+++ b/drivers/net/ethernet/freescale/fec_main.c
@@ -76,6 +76,10 @@ static void fec_enet_itr_coal_init(struct net_device *ndev);
 
 #define FEC_ENET_GET_QUQUE(_x) ((_x == 0) ? 1 : ((_x == 1) ? 2 : 0))
 
+#define AVB_FIQ_EXTENSION
+#define AVB_FIQ_RESERVED_RXQ 1
+#define AVB_FIQ_RESERVED_TXQ 0
+
 /* Pause frame feild and FIFO threshold */
 #define FEC_ENET_FCE	(1 << 5)
 #define FEC_ENET_RSEM_V	0x84
@@ -804,7 +808,7 @@ static void fec_enet_bd_init(struct net_device *dev)
 	unsigned int i;
 	unsigned int q;
 
-	for (q = 0; q < fep->num_rx_queues; q++) {
+	for (q = 0; q < fep->num_rx_queues_served; q++) {
 		/* Initialize the receive buffer descriptors. */
 		rxq = fep->rx_queue[q];
 		bdp = rxq->bd.base;
@@ -826,7 +830,7 @@ static void fec_enet_bd_init(struct net_device *dev)
 		rxq->bd.cur = rxq->bd.base;
 	}
 
-	for (q = 0; q < fep->num_tx_queues; q++) {
+	for (q = 0; q < fep->num_tx_queues_served; q++) {
 		/* ...and the same for transmit */
 		txq = fep->tx_queue[q];
 		bdp = txq->bd.base;
@@ -861,7 +865,7 @@ static void fec_enet_active_rxring(struct net_device *ndev)
 	struct fec_enet_private *fep = netdev_priv(ndev);
 	int i;
 
-	for (i = 0; i < fep->num_rx_queues; i++)
+	for (i = 0; i < fep->num_rx_queues_served; i++)
 		writel(0, fep->rx_queue[i]->bd.reg_desc_active);
 }
 
@@ -872,7 +876,7 @@ static void fec_enet_enable_ring(struct net_device *ndev)
 	struct fec_enet_priv_rx_q *rxq;
 	int i;
 
-	for (i = 0; i < fep->num_rx_queues; i++) {
+	for (i = 0; i < fep->num_rx_queues_served; i++) {
 		rxq = fep->rx_queue[i];
 		writel(rxq->bd.dma, fep->hwp + FEC_R_DES_START(i));
 		writel(PKT_MAXBUF_SIZE, fep->hwp + FEC_R_BUFF_SIZE(i));
@@ -883,14 +887,21 @@ static void fec_enet_enable_ring(struct net_device *ndev)
 			       fep->hwp + FEC_RCMR(i));
 	}
 
-	for (i = 0; i < fep->num_tx_queues; i++) {
+	for (i = 0; i < fep->num_tx_queues_served; i++) {
 		txq = fep->tx_queue[i];
 		writel(txq->bd.dma, fep->hwp + FEC_X_DES_START(i));
+	}
 
+	/* Enable DMAs for additional queues
+	- queue 0 is enabled by default but other queues
+	  require to be explicitly enabled
+	- the DMA is shared by RX and TX queues so enable
+	  it if at least one of them exists
+	- it must be done before enabling the controller */
+	for (i = 1; (i < fep->num_tx_queues) || (i < fep->num_rx_queues); i++) {
 		/* enable DMA1/2 */
-		if (i)
-			writel(DMA_CLASS_EN | IDLE_SLOPE(i),
-			       fep->hwp + FEC_DMA_CFG(i));
+		writel(DMA_CLASS_EN | IDLE_SLOPE(i),
+		       fep->hwp + FEC_DMA_CFG(i));
 	}
 }
 
@@ -900,7 +911,7 @@ static void fec_enet_reset_skb(struct net_device *ndev)
 	struct fec_enet_priv_tx_q *txq;
 	int i, j;
 
-	for (i = 0; i < fep->num_tx_queues; i++) {
+	for (i = 0; i < fep->num_tx_queues_served; i++) {
 		txq = fep->tx_queue[i];
 
 		for (j = 0; j < txq->bd.ring_size; j++) {
@@ -2727,7 +2738,7 @@ static void fec_enet_free_buffers(struct net_device *ndev)
 	struct fec_enet_priv_rx_q *rxq;
 	unsigned int q;
 
-	for (q = 0; q < fep->num_rx_queues; q++) {
+	for (q = 0; q < fep->num_rx_queues_served; q++) {
 		rxq = fep->rx_queue[q];
 		bdp = rxq->bd.base;
 		for (i = 0; i < rxq->bd.ring_size; i++) {
@@ -2744,7 +2755,7 @@ static void fec_enet_free_buffers(struct net_device *ndev)
 		}
 	}
 
-	for (q = 0; q < fep->num_tx_queues; q++) {
+	for (q = 0; q < fep->num_tx_queues_served; q++) {
 		txq = fep->tx_queue[q];
 		bdp = txq->bd.base;
 		for (i = 0; i < txq->bd.ring_size; i++) {
@@ -2763,7 +2774,7 @@ static void fec_enet_free_queue(struct net_device *ndev)
 	int i;
 	struct fec_enet_priv_tx_q *txq;
 
-	for (i = 0; i < fep->num_tx_queues; i++)
+	for (i = 0; i < fep->num_tx_queues_served; i++)
 		if (fep->tx_queue[i] && fep->tx_queue[i]->tso_hdrs) {
 			txq = fep->tx_queue[i];
 			dma_free_coherent(&fep->pdev->dev,
@@ -2772,9 +2783,9 @@ static void fec_enet_free_queue(struct net_device *ndev)
 					  txq->tso_hdrs_dma);
 		}
 
-	for (i = 0; i < fep->num_rx_queues; i++)
+	for (i = 0; i < fep->num_rx_queues_served; i++)
 		kfree(fep->rx_queue[i]);
-	for (i = 0; i < fep->num_tx_queues; i++)
+	for (i = 0; i < fep->num_tx_queues_served; i++)
 		kfree(fep->tx_queue[i]);
 }
 
@@ -2785,7 +2796,7 @@ static int fec_enet_alloc_queue(struct net_device *ndev)
 	int ret = 0;
 	struct fec_enet_priv_tx_q *txq;
 
-	for (i = 0; i < fep->num_tx_queues; i++) {
+	for (i = 0; i < fep->num_tx_queues_served; i++) {
 		txq = kzalloc(sizeof(*txq), GFP_KERNEL);
 		if (!txq) {
 			ret = -ENOMEM;
@@ -2810,7 +2821,7 @@ static int fec_enet_alloc_queue(struct net_device *ndev)
 		}
 	}
 
-	for (i = 0; i < fep->num_rx_queues; i++) {
+	for (i = 0; i < fep->num_rx_queues_served; i++) {
 		fep->rx_queue[i] = kzalloc(sizeof(*fep->rx_queue[i]),
 					   GFP_KERNEL);
 		if (!fep->rx_queue[i]) {
@@ -2912,11 +2923,11 @@ static int fec_enet_alloc_buffers(struct net_device *ndev)
 	struct fec_enet_private *fep = netdev_priv(ndev);
 	unsigned int i;
 
-	for (i = 0; i < fep->num_rx_queues; i++)
+	for (i = 0; i < fep->num_rx_queues_served; i++)
 		if (fec_enet_alloc_rxq_buffers(ndev, i))
 			return -ENOMEM;
 
-	for (i = 0; i < fep->num_tx_queues; i++)
+	for (i = 0; i < fep->num_tx_queues_served; i++)
 		if (fec_enet_alloc_txq_buffers(ndev, i))
 			return -ENOMEM;
 	return 0;
@@ -3250,7 +3261,7 @@ static int fec_enet_init(struct net_device *ndev)
 	fec_set_mac_address(ndev, NULL);
 
 	/* Set receive and transmit descriptor base. */
-	for (i = 0; i < fep->num_rx_queues; i++) {
+	for (i = 0; i < fep->num_rx_queues_served; i++) {
 		struct fec_enet_priv_rx_q *rxq = fep->rx_queue[i];
 		unsigned size = dsize * rxq->bd.ring_size;
 
@@ -3266,7 +3277,7 @@ static int fec_enet_init(struct net_device *ndev)
 		rxq->bd.last = (struct bufdesc *)(((void *)cbd_base) - dsize);
 	}
 
-	for (i = 0; i < fep->num_tx_queues; i++) {
+	for (i = 0; i < fep->num_tx_queues_served; i++) {
 		struct fec_enet_priv_tx_q *txq = fep->tx_queue[i];
 		unsigned size = dsize * txq->bd.ring_size;
 
@@ -3485,6 +3496,19 @@ fec_probe(struct platform_device *pdev)
 		goto failed_ioremap;
 	}
 
+#ifdef AVB_FIQ_EXTENSION
+	if (num_rx_qs < 2) {
+		ret = -ENOMEM;
+		goto failed_avb;
+	}
+	/* Save one Rx queue for AVB */
+	fep->num_rx_queues_served = num_rx_qs - AVB_FIQ_RESERVED_RXQ;
+	fep->num_tx_queues_served = num_tx_qs - AVB_FIQ_RESERVED_TXQ;
+#else
+	fep->num_rx_queues_served = num_rx_qs;
+	fep->num_tx_queues_served = num_tx_qs;
+#endif
+
 	fep->pdev = pdev;
 	fep->dev_id = dev_id++;
 
@@ -3671,6 +3695,9 @@ fec_probe(struct platform_device *pdev)
 	of_node_put(phy_node);
 failed_phy:
 	dev_id--;
+#ifdef AVB_FIQ_EXTENSION
+failed_avb:
+#endif
 failed_ioremap:
 	free_netdev(ndev);
 
-- 
2.11.0
